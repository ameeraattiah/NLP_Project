{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8639ba53-5532-42a4-b915-8f0bcc6f570e",
   "metadata": {},
   "source": [
    "# Academic Specific Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515cfe8-5b18-47cc-9c68-afda621eeb48",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a68a2-067b-452a-9018-86d08c09d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch\n",
    "!pip install transformers torch scikit-learn\n",
    "!pip install ipywidgets --upgrade\n",
    "!pip install datasets --upgrade\n",
    "!pip install pyarrow --upgrade\n",
    "!pip install huggingface_hub\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install scikit-learn\n",
    "!pip install datasets\n",
    "!pip install datasketch\n",
    "!pip install transformers[torch] accelerate\n",
    "!pip install ipywidgets\n",
    "!pip install ipywidgets\n",
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "!pip install requests\n",
    "!pip install tiktoken\n",
    "!pip install sentencepiece\n",
    "!pip install --upgrade notebook ipywidgets\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db7996-8ec7-42b1-ac47-d29c6fd3c556",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ee16d-6cad-428c-92ed-f1fa7528d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()\n",
    "\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import T5Tokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "\n",
    "print(\"SentencePiece is installed and ready to use.\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e15c5-e9c9-4eef-926a-18a8ded32897",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935c554-60fa-4163-8894-fff8fadfa5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model_name\": \"UBC-NLP/araT5-base\",  # Load AraT5 locally\n",
    "    \"fine_tune_model\": \"aubmindlab/bert-base-arabertv02\",  # Model to fine-tune\n",
    "    \"threshold\": 3,  # Minimum score for high-quality content\n",
    "    \"annotation_samples\": 100,  # Total number of samples annotated with AraT5.\n",
    "    \"validation_samples\": 30,  # Subset of annotation_samples reserved for validation\n",
    "    \"max_samples_to_fine_tune\": 70,  # Maximum annotated samples used for fine-tuning\n",
    "    \"epochs\": 5,  # Fine-tuning epochs\n",
    "    \"batch_size\": 4,  # Lower the batch size to reduce memory usage\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f135a-83a1-44d6-a7a8-fe219f2ce729",
   "metadata": {},
   "source": [
    "## Arabic Rubric Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d9c22-b051-42bb-84f8-c9b5b181c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_prompt = \"\"\"\n",
    "فيما يلي مقتطف من صفحة ويب. قم بتقييم ما إذا كانت الصفحة ذات قيمة تعليمية عالية ويمكن أن تكون مفيدة في بيئة تعليمية لتدريس المستويات من المرحلة الابتدائية إلى المرحلة الإعدادية باستخدام نظام تقييم مكون من 5 نقاط تراكمية وفقًا للمعايير التالية:\n",
    "أضف نقطة واحدة إذا كان المقتطف يقدم بعض المعلومات الأساسية ذات الصلة بالموضوعات التعليمية، حتى لو تضمن محتوى غير ذي صلة أو غير أكاديمي مثل الإعلانات والمواد الترويجية.\n",
    "•\tأضف نقطة أخرى إذا كان المقتطف يتناول بعض العناصر ذات الصلة بالتعليم ولكنه لا يتماشى بشكل وثيق مع المعايير التعليمية. قد يخلط بين المحتوى التعليمي وغير التعليمي، ويقدم نظرة عامة سطحية عن موضوعات قد تكون مفيدة، أو يعرض المعلومات بطريقة غير منظمة وأسلوب كتابة غير واضح.\n",
    "•\tامنح نقطة ثالثة إذا كان المقتطف مناسبًا للاستخدام التعليمي ويقدم مفاهيم رئيسية ذات صلة بالمناهج المدرسية. يكون المحتوى واضحًا ولكنه قد لا يكون شاملاً، أو قد يتضمن بعض المعلومات الزائدة. قد يشبه القسم التمهيدي لكتاب مدرسي أو درس تعليمي بسيط مناسب للتعلم ولكنه يحتوي على بعض القيود مثل معالجة مفاهيم معقدة جدًا لطلاب المرحلة الإعدادية.\n",
    "•\tامنح نقطة رابعة إذا كان المقتطف ذا صلة كبيرة ومفيدًا للأغراض التعليمية لمستوى لا يتجاوز المرحلة الإعدادية، مع أسلوب كتابة واضح ومتسق. يمكن أن يشبه فصلًا من كتاب مدرسي أو درسًا تعليميًا، حيث يقدم محتوى تعليميًا غنيًا، بما في ذلك التمارين والحلول، مع الحد الأدنى من المعلومات غير ذات الصلة، والمفاهيم ليست معقدة للغاية لطلاب هذه المرحلة. يكون المحتوى منظمًا ومركّزًا وقيمًا للتعلم المنهجي.\n",
    "•\tامنح نقطة خامسة إذا كان المقتطف ممتازًا في قيمته التعليمية ومناسبًا تمامًا للتدريس في المرحلة الابتدائية أو الإعدادية. يتبع المقتطف منطقًا تفصيليًا، وأسلوب الكتابة سهل الفهم، ويقدم رؤى عميقة وشاملة حول الموضوع دون أي محتوى غير تعليمي أو معقد.\n",
    "المقتطف: <EXAMPLE>. بعد فحص المقتطف:\n",
    "•\tبرر بإيجاز مجموع النقاط، بحد أقصى 100 كلمة.\n",
    "•\tاختتم بالنقاط الإجمالية بالتنسيق التالي: \"التقييم التعليمي: <مجموع النقاط>\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928c3ef-61cd-41d7-a3ed-895a08efcba1",
   "metadata": {},
   "source": [
    "## Custom Dataset Class\n",
    "standardizes the process of preparing text data for machine learning models by tokenizing text, truncating or padding sequences to a fixed length, and formatting inputs and labels into PyTorch tensors. This enables efficient batching and compatibility with PyTorch's DataLoader for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd12c3-8d40-4f1d-ad63-6a7a789f265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5c91b-94c1-4315-aad9-7495da630f3f",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f02582-a699-4717-a332-b663363d53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return [{\"text\": item[\"text\"], \"metadata\": item[\"metadata\"]} for item in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37df89-e9a9-43a8-9889-1319e8642432",
   "metadata": {},
   "source": [
    "## Step 2: Annotate Data Locally with AraT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864b730-1edf-4370-a812-e9369423cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_samples(samples, model_name):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    annotated_data = []\n",
    "\n",
    "    for sample in samples:\n",
    "        text = sample[\"text\"]\n",
    "        prompt = arabic_prompt.format(text=text)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        outputs = model.generate(**inputs, max_length=100)\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        scores = extract_scores(result)\n",
    "        annotated_data.append({\"text\": text, \"scores\": scores, \"metadata\": sample[\"metadata\"]})\n",
    "\n",
    "    return annotated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c587b41-8e9e-4e21-8a9f-6e8933cd52f0",
   "metadata": {},
   "source": [
    "## Extract Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f79a22-b98b-45a9-9535-7617314ae1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scores(output):\n",
    "    lines = output.split(\"\\n\")\n",
    "    scores = {}\n",
    "    for line in lines:\n",
    "        if \"ملاءمة\" in line:\n",
    "            scores[\"relevance\"] = int(line.split(\":\")[-1].strip())\n",
    "        elif \"وضوح\" in line:\n",
    "            scores[\"clarity\"] = int(line.split(\":\")[-1].strip())\n",
    "        elif \"عمق\" in line:\n",
    "            scores[\"depth\"] = int(line.split(\":\")[-1].strip())\n",
    "    total = sum(scores.values())\n",
    "    scores[\"total\"] = total\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda99a7-f9e0-4f84-bb02-ef0e7b1d0f24",
   "metadata": {},
   "source": [
    "## Step 3: Fine-Tune AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb1e7a-35f7-4d95-b2d8-d8ab8c0b9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_arabert(train_data, tokenizer, model):\n",
    "    texts = [item[\"text\"] for item in train_data]\n",
    "    labels = [item[\"scores\"][\"total\"] for item in train_data]\n",
    "\n",
    "    dataset = CustomDataset(texts, labels, tokenizer)\n",
    "    model.to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=config[\"epochs\"],\n",
    "        per_device_train_batch_size=config[\"batch_size\"],\n",
    "        save_steps=10_000,\n",
    "        save_total_limit=2,\n",
    "        no_cuda=True,\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    trainer.train()\n",
    "    print(\"Fine-tuning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0d915a-d6a1-4aaf-bb9c-b3a76deff20e",
   "metadata": {},
   "source": [
    "## Step 4: Predict with Fine-Tuned AraBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd8f94-37a4-4ec1-9d29-79fc68eba96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_arabert(unlabeled_data, model, tokenizer):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "\n",
    "    for sample in unlabeled_data:\n",
    "        text = sample[\"text\"]\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = logits.argmax(dim=-1).item()\n",
    "\n",
    "        predictions.append({\"text\": text, \"predicted_score\": predicted_label, \"metadata\": sample[\"metadata\"]})\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6489a8-dac1-4ca9-b3c4-afe3b8ca4f83",
   "metadata": {},
   "source": [
    "## Step 5: Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28462c88-9d9b-47ef-b446-f3496dcabc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(validation_data, model, tokenizer):\n",
    "    model.to(device)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for item in validation_data:\n",
    "        text = item[\"text\"]\n",
    "        true_labels.append(item[\"scores\"][\"total\"])\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_label = logits.argmax(dim=-1).item()\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    f1 = f1_score(true_labels, predicted_labels, average=\"macro\")\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(true_labels, predicted_labels, average=\"macro\", zero_division=0)\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    print(f\"Validation F1 Score: {f1:.2f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Validation Precision: {precision:.2f}\")\n",
    "    print(f\"Validation Recall: {recall:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078a2d6-bdc4-4ff1-b358-979d60a1fc8d",
   "metadata": {},
   "source": [
    "## Step 6: Filter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633d611-7889-40ef-991d-3371db43a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(annotated_data, threshold):\n",
    "    return [\n",
    "        doc for doc in annotated_data\n",
    "        if doc[\"predicted_score\"] >= threshold\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a873f-f5cf-46c4-8abf-126e2e5cab83",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a75351-5088-4a12-afa7-1aed2643469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline():\n",
    "    # Step 1: Load the dataset from a specified JSON file\n",
    "    dataset = load_dataset(\"/Users/ameeraattiah/Desktop/arabicweb24/jeje.json\")\n",
    "    print(f\"Loaded {len(dataset)} samples.\")\n",
    "\n",
    "    # Step 2: Select a subset of the dataset for annotation\n",
    "    sample_data = dataset[:config[\"annotation_samples\"]]\n",
    "    annotated_data = annotate_samples(sample_data, config[\"model_name\"])\n",
    "    print(f\"Annotated {len(annotated_data)} samples.\")\n",
    "\n",
    "    # Step 3: Load the tokenizer and model for fine-tuning\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config[\"fine_tune_model\"])\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(config[\"fine_tune_model\"], num_labels=6)\n",
    "\n",
    "    # Step 4: Fine-tune the model using the annotated data\n",
    "    fine_tune_arabert(annotated_data, tokenizer, model)\n",
    "\n",
    "    # Step 5: Use the fine-tuned model to predict the remaining dataset\n",
    "    remaining_data = dataset[config[\"annotation_samples\"]:]\n",
    "    predictions = predict_with_arabert(remaining_data, model, tokenizer)\n",
    "    print(f\"Predicted {len(predictions)} samples with fine-tuned AraBERT.\")\n",
    "\n",
    "    # Step 6: Validate the fine-tuned model on a subset of the annotated data\n",
    "    validation_data = annotated_data[:config[\"validation_samples\"]]\n",
    "    validate_model(validation_data, model, tokenizer)\n",
    "\n",
    "    # Step 7: Filter the predictions to include only high-quality samples\n",
    "    filtered_data = filter_dataset(predictions, config[\"threshold\"])\n",
    "    print(f\"Filtered dataset contains {len(filtered_data)} high-quality samples.\")\n",
    "\n",
    "    # Step 8: Save the filtered data to a JSON file for future use\n",
    "    with open(\"/Users/ameeraattiah/Desktop/arabicweb24/jeje-edu.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(filtered_data, file, ensure_ascii=False, indent=4)\n",
    "    print(\"Filtered data saved.\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n",
    "    print(\"Running academic dataset processing...\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
